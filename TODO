DONE

	Work out why gateway can't decrypt the packet...

	Move crypto stuff into core.go

	Implement a simple encrypt/decrypt test.

	The wrong keygen was being used. Fixed with core.Keygen

	Forward packet from gateway to server, with the prefix/postfix stripped off

	(server does not need chonkle, pittle, or any of the crypto stuff...)

	Print out the session id and sequence number received on the server.

	The server should be able to send packets down to the client

	In order to do this, there needs to be a separate *internal* socket on the gateway, for the server to send packets to, which will be sent back down to the client...

	This is because the client NAT will *not* function unless the client receives packets back from the same address it sent packets to.

	This implies that the client gateway cannot be behind a UDP load balancer...

	For the moment, code assuming that there is a single instance of the gateway.

	But there is definitely complexity here, if the gateway can't be behind a udp load balancer.

	This is kinda annoying.

	-----------

	Start with the simplest thing which is a second internal socket, that receives packets sent to it from teh server, and forwards them back down to the client, via the gateway socket, so NAT works.

	To make this work transparently, the gateway should include the internal address to send packets back to at the front of the payload packet.

	This way the server need not know anything about the gateway or make any decisions about how to reply to. It is stateless.

	-----------

	Cool solution that enables UDP load balancing to work with NAT.

	https://cloud.google.com/architecture/udp-with-network-load-balancing

	It's possible to rewrite the source address so it returns the address of the LB, not the VM.

	This will enable the gateway to have a UDP load balancer in front of it, and to horizontally scale!

	-----------

	Add concept of internal address (and port) for gateway.

	Bring across code to read/write address and make sure it's fixed size.

	It is 19 bytes, whether ipv4 or ipv6, just how I want it.

	Packets sent from gateway to server should include both:

	 - internal gateway address for responses to go to
	 - address + port of the client corresponding to the packet

	Extend server to read past the internal gateway address and the client address, to get payload.

	Extend server to respond to the gateway internal address, with a dummy 100 byte payload prefixed by the client address.

	------------------------

	Implement a challenge/response with a token that is passed back and forth.

	This lets a new gateway see that this is a real authenticated session, even if it is a new instance.

	What if somebody replays old packets from an existing session?

	They should really have to prove with a challenge/response that they know the private key.

	Without this, it's not possible to securely hand over to a new instance.

	Otherwise, an attacker can take whatever token I pass back and forth, and use it to intercept a stream (within some time, even if only 10 seconds...), and insert messages into the stream.

	This cannot be avoided, without a challenge response that proves the new stream knows the session id

	I think this means it's not possible to securely migrate a session, without an RTT challenge/response.

	I should rethink what is possible in migration. It's still possible to migrate with awareness that the old gateway is going away, but if the gateway shuts down cold or crashes, the migration will be disruptive at best (RTT multiple challenge/response).

	------------------------

	Extend the gateway to open sockets on the internal address.

	When a packet is received on the gateway internal address, read the client address from the first 19 bytes and forward the rest of the packet to the client.

	Verify the client receives the dummy 100 byte payload from the server.

	The client receives the 100 byte payload on the internal address.

	Change it so that the packet is forwarded from the public address sockets.

	This implies that there is a one-to-one ratio of internal and public sockets on the gateway, eg. internal[i] -> public[i] socket for sending.

	Verify the client gets the 100 byte payload from the gateway address 127.0.0.1:40000 not 40001 (internal).

	------------------------
	
	Implement a challenge response before the gateway is allowed to forward packets to the server.

	This can be done with a small crypto token that gets refreshed periodically...

	If the token is absent, then a challenge/response can be performed.

	If the token is invalid or stale, then the packet can be dropped.

	(How to restrict this challenge/response so that it only is sent say, once per-second, no matter how many challenges are sent for this session id, or address?)

	(Attack on this protocol. Send many small but valid "knocks" to the server, and create instances of sessions that don't convert, or convert to valid as slowly as possible...)

	This seems to have a lot of parallels to HTTP attacks...

	------------------------

	Make sure the challenge packet is smaller than the minimal packet that could trigger a challenge to be sent out. (no DDoS amplification).

	------------------------

	Server receives valid packet from session id

	Look up a session entry by session id

	If the entry exists, grab the data and do the reliability stuff.

	If the entry doesn't exist, send a challenge packet back to the client. This challenge packet must be smaller than minimum packet packet from client -> gateway.

	In the challenge packet, include some encrypted token data (including timestamp and perhaps some number to be incremented?) and sign it with a random "challenge" keypair on the server (held fixed at the beginning of the server start), and the public key of the session. Include the internal public key in the challenge packet (since otherwise the client won't know it).

	Client receives the challenge packet, and can only decrypt it with its private key.

	Client decrypts the challenge token, makes some trivial modification, eg. adds one to a number, and encodes it back with the private key of the session, and the public key of the "challenge" keypair for the server.

	The server receives the response packet, checks that it decrypts -- now it knows that the sender knows the private key (does it need to include some data for safety to be checked? timestamp? initial sequence number?)

	Now the server adds a session entry indexed by session id.

	Next time a packet comes through, the server won't respond with a challenge packet, it will actually process packets.

	In order for this to work, we may need to set some minimum payload size on packets, eg. 1000 bytes

	To try to get a 10X reduction in response size to challenges.

	If this isn't enough, then a connecting client needs some sort of token from the backend, to allow it in, and this token can get periodically refreshed while the client is connected. But this can be designed later...

	------------------------

	Add a zero byte in front of the chonkle for future proofing

	------------------------

	There should be a version number in front of the server -> gateway packet, so we can upgrade the format, without bringing the system down.

	------------------------

	There should also be a version number in front of the gateway -> server packet.

	------------------------

	Should there also be a version in front of the gateway -> client packet? Not sure yet. Pass for now.

	------------------------

	Determine and enforce the minimum payload size (1000 bytes)

	------------------------

	Security concern. Client generates private/public keypair, and knowing this goes wide across a bot net. Is there anything we can do here? Probably not. Would it cause problems? Potentially yes, but is it really any different from botnet with different keypairs generated? Not really.

	------------------------

	Purpose of challenge and response:

		1. Ensure that an actual client which knows the private key for the session is on the other end of the address, before forwarding packets from the gateway to the server.

		2. To allow the client session can seamlessly transition from one gateway instance to another, in case a gateway instance goes down, or load balancing points the session at another gateway.

		3. To avoid somebody being able to capture and replay packets from breaking the client session, eg. by capturing a packet and then load balancing to a different gateway, it must not be possible for the hijacker to inject old packets into the session stream.

	------------------------

	Since the client must sign the response with the private key, it seems that the contents of the challenge may be completely moot.

	But this is not true, since there must be some hash that is verifiable statelessly as being real.

	My suggestion would be to encrypt the following data in the token:

		1. client address + port 
		2. gateway address + port 
		3. timestamp (such that old challenge tokens can be ignored if > n seconds old)

	Then this token is encrypted in such a way (with a private key known only to the gateway instance...) and passed down as the challenge, encrypted with private/public keypair again.

	This way even though the client must be able to decrypt the token outer, it cannot decrypt the token inner and spoof it.

	So the challenge/response is secure.

	------------------------

TODO

	-------------

	We also need a packet type byte

	This packet type byte should be for the internal protocol only

	so far:

		0: payload packet (regular packet, delivering events...)
		1: challenge packet
		2: challenge response packet

	Any packet received that is unknown on the gateway (no corresponding session entry), gets a response with a challenge packet.

	The challenge packet must be small relative to any regular packet that can trigger it, to avoid DDoS amplification.

	-------------

	Implement challenge token

	Add challenge token to core.go with tests

	Model it on the encryption used for connect token, but obviously totally different contents in the token.

	-------------

	Add a session map to each gateway shard via SO_REUSEPORT (no contention = no locks)

	Process one packet at a time, so no contention or ordering issues wrt. packet processing.

	If there is no entry in the session map, respond with a challenge packet.

	If there is an entry in the session map, update the timeout... and pass the packet through to the server.

	-------------

	What if we just had the gateway flip every minute or so, to a new "instance" of teh session database via pointer swap, per-shard.

	Then sessions could migrate to the new session entry (driven by packet send/recv) every minute, and we wouldn't ever need to walk the structure.

	We'd need a way to do this migration, without any RTT disruption...

	This could be done by overlapping old and new maps for the transition period.

	First check if in new, then check if in old, but always insert and update in new, when found.

	This is an AWESOME way to do timeouts without O(n) walk.

	-------------





















	------------------------

	Interesting question. Where does the server sequence come from, for server -> client packets?

	It can't really actually be stateless, so it must support upgrading when the gateway changes.

	The idea I think here is that we can have a token sent back down to the client, and reflected back up (most recent token), and this will provide an anchor for the server sequence updated say at round trip, or once per-second.

	------------------------

	I think this whole state and token thing sort of requires the challenge/response to be done, to determine a real connection, and to persist that connection in some manner that is stateless.

	This seems to be the important thing to do next, since it is foundational for everything else.

	------------------------

	OK. Now that the server is getting the payloads that it needs, it's time to think about the server.

	The job of the server is to:

		a) only respond to clients who have a real connection (eg. challenge/response...)

		b) "instantly" transition a client from one IP:port to another without any delays or hitches in packet delivery.

		c) "instantly" transition from one server instance to another, in the case of a server instance failing, going down, becoming unhealthy or crashing out, without any delays or hitches in packet delivery.

		d) be stateless as much as possible, so server instances can be scaled out horizontally.

		e) only accept messages that conform to the schema of the server (eg. the set of messages that the client may send to the server...)

		f) queue up messages to an internal message processing system, on some fully reliable packet delivery system (be it TCP, HTTPS batched, zeromq, whatever...), and only ack packets sent from the client when they have been guaranteed delivered via the queue system.

		g) send down packets to the client including acks and ack_bits, so the client knows what packets have been received by the server, and what packets were dropped.

	------------------------

	Cool golang stuff to research...

	https://dev.to/panjf2000/releasing-a-high-performance-lightweight-non-blocking-and-event-loop-networking-library-written-in-pure-go-4beb

	https://dev.to/panjf2000/releasing-a-high-performance-goroutine-pool-in-go-n57

	https://golangrepo.com/repo/lesismal-nbio-go-network#nbio---non-blocking-io